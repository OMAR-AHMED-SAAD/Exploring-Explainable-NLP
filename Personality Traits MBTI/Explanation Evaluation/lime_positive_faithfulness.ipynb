{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: nvidia-smi\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roberta Base Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('../datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the model name\n",
    "PRE_TRAINED_MODEL_NAME = 'roberta-base'\n",
    "\n",
    "# setting the dataset\n",
    "dataset='MBTI 500 multi_label.csv'\n",
    "\n",
    "\n",
    "# setting the data path\n",
    "if os.path.exists(f'/datasets/mbti/{dataset}'):\n",
    "    DATAPATH=f'/datasets/mbti/{dataset}'\n",
    "else:\n",
    "    DATAPATH=f'../data/{dataset}'\n",
    "\n",
    "# setting the checkpoint path \n",
    "if os.path.exists('ckpts'):\n",
    "    CHECKPOINTPATH = 'ckpts/Persnality_MBTI'\n",
    "else:\n",
    "    CHECKPOINTPATH = '../ckpts/Persnality_MBTI'\n",
    "\n",
    "# training parameters\n",
    "MAX_LEN = 512\n",
    "\n",
    "# TOKENIZER\n",
    "tokenizer = AutoTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "\n",
    "# setting the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# setting the random seed\n",
    "torch.manual_seed(99)\n",
    "torch.cuda.manual_seed(99)\n",
    "torch.cuda.manual_seed_all(99)\n",
    "np.random.seed(99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../data/MBTI 500 multi_label.csv',\n",
       " '../ckpts/Persnality_MBTI',\n",
       " device(type='cpu'))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATAPATH,CHECKPOINTPATH,device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('save_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_list = ['IE', 'NS', 'TF', 'JP']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/omarahmed/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/omarahmed/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# import model\n",
    "import sys\n",
    "sys.path.append('../Models')\n",
    "import MBTI_model_lime as model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roberta-base_no_words loaded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x14ad7c750>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_no_words = model.ROBERTAClass(PRE_TRAINED_MODEL_NAME)\n",
    "model_no_words.load_state_dict(torch.load(CHECKPOINTPATH + f'_clean_Best_{PRE_TRAINED_MODEL_NAME}.bin', map_location=torch.device(device)))\n",
    "model_no_words.to(device)\n",
    "print(f'{PRE_TRAINED_MODEL_NAME}_no_words loaded')\n",
    "model_no_words.eval()\n",
    "\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get First 100 correct predictions with equal distribution of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the correct predictions \n",
    "df_correct = df[(df['IE']==df['IE_true']) & (df['NS']==df['NS_true']) & (df['TF']==df['TF_true']) & (df['JP']==df['JP_true'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9m/_z9mps5d1f70mpcggw5t_pxm0000gn/T/ipykernel_86477/3501893555.py:9: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if row[i]==0:\n",
      "/var/folders/9m/_z9mps5d1f70mpcggw5t_pxm0000gn/T/ipykernel_86477/3501893555.py:26: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  extracted_df=pd.concat([extracted_df,df_correct.iloc[[i]]],ignore_index=True)\n",
      "/var/folders/9m/_z9mps5d1f70mpcggw5t_pxm0000gn/T/ipykernel_86477/3501893555.py:15: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if row[i]==0:\n"
     ]
    }
   ],
   "source": [
    "extracted_df = pd.DataFrame(columns=df_correct.columns)\n",
    "# sort with rows that has 1 in IE, 1 in NS, 1 in TF, 1 in JP\n",
    "df_correct = df_correct.sort_values(by=['IE','NS','TF','JP'],ascending=False)\n",
    "# count 0s and 1s\n",
    "count_0 = [0,0,0,0]\n",
    "count_1 = [0,0,0,0]\n",
    "def increment_count(row):\n",
    "    for i in range(4):\n",
    "        if row[i]==0:\n",
    "            count_0[i]+=1\n",
    "        else:\n",
    "            count_1[i]+=1\n",
    "def decrement_count(row):\n",
    "    for i in range(4):\n",
    "        if row[i]==0:\n",
    "            count_0[i]-=1\n",
    "        else:\n",
    "            count_1[i]-=1            \n",
    "for i in range(len(df_correct)):\n",
    "    increment_count(df_correct.iloc[i][1:5])\n",
    "    # if any of the counts is greater than 50, do not add the row to the extracted_df\n",
    "    if count_0[0]>50 or count_0[1]>50 or count_0[2]>50 or count_0[3]>50 or count_1[0]>50 or count_1[1]>50 or count_1[2]>50 or count_1[3]>50:\n",
    "        decrement_count(df_correct.iloc[i][1:5])\n",
    "        continue\n",
    "    # add the row to the extracted_df\n",
    "    extracted_df=pd.concat([extracted_df,df_correct.iloc[[i]]],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([50, 50, 50, 50], [50, 50, 50, 50])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_0,count_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 9 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   text     100 non-null    object \n",
      " 1   IE       100 non-null    float64\n",
      " 2   NS       100 non-null    float64\n",
      " 3   TF       100 non-null    float64\n",
      " 4   JP       100 non-null    float64\n",
      " 5   IE_true  100 non-null    float64\n",
      " 6   NS_true  100 non-null    float64\n",
      " 7   TF_true  100 non-null    float64\n",
      " 8   JP_true  100 non-null    float64\n",
      "dtypes: float64(8), object(1)\n",
      "memory usage: 7.2+ KB\n"
     ]
    }
   ],
   "source": [
    "extracted_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'IE': 1.0, 'NS': 1.0, 'TF': 1.0, 'JP': 1.0}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the accuracy of the extracted_df\n",
    "def get_accuracy_extracted_df(df,labels_list):\n",
    "    accuracy = {}\n",
    "    for label in labels_list:\n",
    "        accuracy[label] = (df[label]==df[label+'_true']).sum()/len(df)\n",
    "    return accuracy\n",
    "\n",
    "get_accuracy_extracted_df(extracted_df,labels_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "lime_explanation_IE= model.explain_model(model_no_words, extracted_df[\"text\"],aspect='IE')\n",
    "# save the explanation to a pkl file\n",
    "with open('lime_explanation_IE.pkl', 'wb') as f:\n",
    "    pickle.dump(lime_explanation_IE, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lime_explanation_NS= model.explain_model(model_no_words, extracted_df[\"text\"],aspect='NS')\n",
    "# save the explanation to a pkl file\n",
    "with open('lime_explanation_NS.pkl', 'wb') as f:\n",
    "    pickle.dump(lime_explanation_NS, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lime_explanation_TF= model.explain_model(model_no_words, extracted_df[\"text\"],aspect='TF')\n",
    "# save the explanation to a pkl file\n",
    "with open('lime_explanation_TF.pkl', 'wb') as f:\n",
    "    pickle.dump(lime_explanation_TF, f)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lime_explanation_JP= model.explain_model(model_no_words, extracted_df[\"text\"],aspect='JP')\n",
    "# save the explanation to a pkl file\n",
    "with open('lime_explanation_JP.pkl', 'wb') as f:\n",
    "    pickle.dump(lime_explanation_JP, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IE\n",
      "[('ne', 0.042200318246221356), ('come', 0.03792475333483115), ('gonna', 0.03591114203671764), ('xxfps', 0.03580061438505622), ('remindme', 0.03285327692308008), ('mountain', -0.028835826201961096), ('superior', 0.027087850434445084), ('intuition', 0.02645462413674346), ('fuck', 0.02530716541660381), ('call', -0.024500213389414282), ('around', 0.02402212728601511), ('actually', 0.02393943019679887), ('snooki', 0.023161856700141568), ('company', 0.022833391867277248), ('another', -0.022794919797993664), ('say', 0.022041486098803756), ('s', -0.021264440574876326), ('sometimes', -0.0210357717783274), ('electronic', 0.02070474849247822), ('itj', -0.020701263747063), ('sense', -0.020039185027198342), ('importance', 0.019880936102095705), ('something', -0.01986346563495163), ('le', 0.019751364093689504), ('either', -0.019733162957734217), ('exposure', -0.019616667791578387), ('like', -0.019107003295604573), ('look', 0.018965085557991194), ('shit', 0.01884696041038901), ('subjective', 0.018537529818627167), ('world', 0.017997152069101453), ('etc', 0.017906039310130923), ('energy', -0.017662087854476302), ('letter', -0.017573716383504173), ('suffocate', -0.017545940538915804), ('feel', -0.01751754906814291), ('betsey', 0.017287971625063635), ('get', 0.017253019362686844), ('place', 0.016835594059180524), ('virtually', 0.01653430800623291), ('different', 0.016495322628115174), ('r', 0.016191960386013057), ('relate', -0.01618069832707151), ('opinion', -0.01615374173117789), ('judge', -0.016089534012622485), ('day', 0.01576731121137415), ('make', -0.01569192695705919), ('figure', 0.015358947705603391), ('dominant', 0.015257013624764226), ('otherwise', 0.014867095427578098), ('base', -0.014780062952742755), ('survive', -0.01467776324009822), ('scholar', 0.014559125609578068), ('experience', -0.014289694930604772), ('afraid', -0.01421673586337443), ('fi', -0.014194568893737214), ('cyrus', 0.014050914986957617), ('whether', 0.01394913833889461), ('decide', 0.013917243775609706), ('right', 0.013867482099041463), ('though', 0.013571941529284608), ('great', -0.013570785214087368), ('deep', -0.01348400452503037), ('awareness', -0.01299332132685299), ('type', 0.012847227850110828), ('ask', 0.012766854983543161), ('animal', -0.012583704160123353), ('grind', 0.012570109025046655), ('emulate', -0.012194919385902826), ('fit', 0.012099679627117076), ('however', -0.01204812561346895), ('misguide', -0.011651909976139317), ('kinda', -0.011593122463982662), ('design', 0.01151484316205468), ('kind', 0.011480207682034293), ('sticky', -0.011438624188534897), ('reason', 0.011244893743550392), ('top', -0.011228337993166387), ('bankrupt', -0.011220760091846199), ('change', 0.011214106663845416), ('player', 0.01117446893826122), ('class', 0.011116934352505424), ('first', 0.011076481323482292), ('else', 0.01105912625522412), ('einstein', -0.010978714371799127), ('fun', 0.010915105915714492), ('personality', 0.01078059502395555), ('dude', 0.010737571703910624), ('bias', 0.01034910101201143), ('every', 0.010307866604434826), ('without', 0.01029280055300915), ('new', 0.010180622356338641), ('pretty', 0.010171560696504567), ('naturally', 0.010071737713999038), ('see', -0.009951056758775795), ('ancient', -0.0099203218945982), ('genre', -0.009875783659054987), ('deserve', 0.009817862186737374), ('demon', -0.009661288971140262), ('people', 0.009620118737276187), ('selection', 0.009603852638191806), ('prove', -0.009592678483865583), ('ur', 0.00952873987305957), ('jesus', -0.00946604714455186), ('contrast', 0.00942505203380319), ('value', 0.009405242113767049), ('doms', 0.00937580458772255), ('christ', -0.009061003778438893), ('artist', -0.009033801286314527), ('explain', 0.00903331166209172), ('sorry', 0.00901280045285928), ('drop', -0.008983424634327487), ('interest', 0.008974362440351826), ('sensor', 0.008913350631869543), ('trivialize', 0.008813678080443924), ('versa', 0.00876643920302268), ('everything', 0.008742309873117943), ('trust', 0.008667976893711777), ('aware', -0.00863245322975811), ('whatever', -0.008540801020250986), ('idiot', 0.008356535403863783), ('clearly', 0.008202774096256265), ('part', -0.008155675117445145), ('miley', -0.008098455635220044), ('cause', -0.008064716605635685), ('illusion', 0.007960001905975745), ('um', 0.007928235673292016), ('become', -0.00782565308563997), ('quite', -0.007755645013520556), ('vice', 0.007745283343155569), ('might', 0.007725788620965604), ('h', 0.007725540161813451), ('money', 0.007631991012975021), ('wise', 0.007617281274615149), ('really', -0.007406424370078628), ('low', 0.007362016194657937), ('wander', -0.007350161036664997), ('undertone', -0.007326290279433201), ('incline', 0.007234859782207916), ('introspection', 0.007233953961434243), ('natural', 0.00710807829040001), ('would', 0.007098775212565853), ('fiered', 0.00697836420906271), ('hour', -0.006908386868319912), ('n', -0.006891215322586341), ('inferior', -0.006863278427783364), ('hm', 0.006841973428097599), ('close', 0.006744490326191078), ('discrimination', -0.006704522420387806), ('u', 0.006665840933546404), ('understand', 0.006582929198911338), ('damn', 0.006518224528337893), ('person', 0.006505522431849651), ('activist', -0.006502065623817732), ('tie', -0.006468896258261087), ('animistic', -0.0064134736701079685), ('brother', 0.006410405669173991), ('etp', 0.00634240130585852), ('self', 0.006255570264877727), ('mechanism', -0.006242161253105829), ('relevant', 0.006239082320246158), ('nothing', -0.005913785951774333), ('also', -0.005811451280180549), ('subreddit', 0.005698394278029847), ('thinker', -0.00568300879560865), ('quote', -0.005681223275047108), ('sister', -0.005650425496403138), ('hang', -0.005637525326615528), ('profile', 0.005624449534963894), ('thing', 0.005608995232756647), ('trash', 0.005599074976466266), ('away', -0.005595601536480323), ('ave', -0.0053757115614310475), ('bore', 0.005374775219125477), ('try', -0.00537310024866574), ('hat', 0.005223919010381411), ('significant', -0.005188905959972016), ('rankly', -0.005073631157251715), ('flair', -0.004989543226379681), ('precisely', -0.004977244489159401), ('shudder', 0.0049676275261715), ('yep', -0.0047676272618042016), ('seem', -0.0047040379632536525), ('nonetheless', -0.00464717713084488), ('glamorous', 0.00447718019783095), ('deal', 0.0043685846443450435), ('lot', 0.004366636475406565), ('irrational', 0.004336883153565657), ('one', 0.0042304420272748005), ('lso', -0.004225694826321966), ('side', 0.004209031923384243), ('mean', 0.004137716429738975), ('se', 0.004052530117871506), ('definition', -0.004037093234718736), ('establishment', 0.003948095101326944), ('eems', -0.0038641562767797824), ('write', 0.0038444034177620074), ('friend', -0.003825014393296223), ('someone', -0.0038032675016374325), ('blake', 0.0037929380466522407), ('nah', -0.0037430960875185497), ('tool', 0.003703015718038016), ('dead', -0.0036330278059219876), ('lenhy', 0.003540884079229823), ('comment', 0.003517374254174595), ('impossible', -0.003468233312695975), ('high', -0.0034633310271399253), ('trap', 0.0034548496739648326), ('hey', 0.00338635594482304), ('need', -0.0032929579040317783), ('think', 0.003193381623599382), ('racist', -0.00310014426719824), ('talk', -0.0030366357193145803), ('f', 0.002978002974550606), ('camilla', 0.002942601067076175), ('maybe', -0.002927630397250469), ('philosopher', -0.0028674370820200206), ('celebritytypes', 0.002841767043579999), ('young', -0.002802271253471868), ('conclusion', -0.002565693480773289), ('skew', 0.0025159715158929088), ('encounter', -0.0024987948298091467), ('deliberation', -0.0024744630420319123), ('question', -0.0023939968680576906), ('anderson', -0.0023641905861048296), ('give', -0.0023586571874985537), ('correct', -0.002319129423334189), ('entirely', -0.0023019980176320334), ('dave', -0.002155243781971124), ('function', -0.001963007546574263), ('implication', -0.0018530583310023927), ('throw', 0.0017390277955241153), ('connection', -0.0016718139564263386), ('attention', -0.0016631109281926386), ('consciously', 0.0016399014389441283), ('imply', -0.0015378220233857203), ('much', 0.0014736582601995087), ('page', 0.0013823319909685528), ('justify', 0.0013276629892864404), ('direction', 0.001114649991780003), ('mistyped', -0.0011003377021015785), ('use', -0.0007323138294462849), ('environment', -0.0006583191242603101), ('confront', -0.0006358263810242126), ('incredible', -0.0004788915550063772), ('vocal', -0.00041050449342003737), ('racism', -0.00036737038870430876), ('bear', 0.00028461733857895266), ('nd', 0.0001946370436654709), ('even', -8.901106106324548e-05)]\n"
     ]
    }
   ],
   "source": [
    "# print the lime explanation\n",
    "print('IE')\n",
    "print(lime_explanation_IE[0].as_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ne', 0.042200318246221356),\n",
       " ('come', 0.03792475333483115),\n",
       " ('gonna', 0.03591114203671764),\n",
       " ('xxfps', 0.03580061438505622),\n",
       " ('remindme', 0.03285327692308008),\n",
       " ('superior', 0.027087850434445084),\n",
       " ('intuition', 0.02645462413674346),\n",
       " ('fuck', 0.02530716541660381),\n",
       " ('around', 0.02402212728601511),\n",
       " ('actually', 0.02393943019679887),\n",
       " ('snooki', 0.023161856700141568),\n",
       " ('company', 0.022833391867277248),\n",
       " ('say', 0.022041486098803756),\n",
       " ('electronic', 0.02070474849247822),\n",
       " ('importance', 0.019880936102095705),\n",
       " ('le', 0.019751364093689504),\n",
       " ('look', 0.018965085557991194),\n",
       " ('shit', 0.01884696041038901),\n",
       " ('subjective', 0.018537529818627167),\n",
       " ('world', 0.017997152069101453),\n",
       " ('etc', 0.017906039310130923),\n",
       " ('betsey', 0.017287971625063635),\n",
       " ('get', 0.017253019362686844),\n",
       " ('place', 0.016835594059180524),\n",
       " ('virtually', 0.01653430800623291),\n",
       " ('different', 0.016495322628115174),\n",
       " ('r', 0.016191960386013057),\n",
       " ('day', 0.01576731121137415),\n",
       " ('figure', 0.015358947705603391),\n",
       " ('dominant', 0.015257013624764226),\n",
       " ('otherwise', 0.014867095427578098),\n",
       " ('scholar', 0.014559125609578068),\n",
       " ('cyrus', 0.014050914986957617),\n",
       " ('whether', 0.01394913833889461),\n",
       " ('decide', 0.013917243775609706),\n",
       " ('right', 0.013867482099041463),\n",
       " ('though', 0.013571941529284608),\n",
       " ('type', 0.012847227850110828),\n",
       " ('ask', 0.012766854983543161),\n",
       " ('grind', 0.012570109025046655),\n",
       " ('fit', 0.012099679627117076),\n",
       " ('design', 0.01151484316205468),\n",
       " ('kind', 0.011480207682034293),\n",
       " ('reason', 0.011244893743550392),\n",
       " ('change', 0.011214106663845416),\n",
       " ('player', 0.01117446893826122),\n",
       " ('class', 0.011116934352505424),\n",
       " ('first', 0.011076481323482292),\n",
       " ('else', 0.01105912625522412),\n",
       " ('fun', 0.010915105915714492),\n",
       " ('personality', 0.01078059502395555),\n",
       " ('dude', 0.010737571703910624),\n",
       " ('bias', 0.01034910101201143),\n",
       " ('every', 0.010307866604434826),\n",
       " ('without', 0.01029280055300915),\n",
       " ('new', 0.010180622356338641),\n",
       " ('pretty', 0.010171560696504567),\n",
       " ('naturally', 0.010071737713999038),\n",
       " ('deserve', 0.009817862186737374),\n",
       " ('people', 0.009620118737276187),\n",
       " ('selection', 0.009603852638191806),\n",
       " ('ur', 0.00952873987305957),\n",
       " ('contrast', 0.00942505203380319),\n",
       " ('value', 0.009405242113767049),\n",
       " ('doms', 0.00937580458772255),\n",
       " ('explain', 0.00903331166209172),\n",
       " ('sorry', 0.00901280045285928),\n",
       " ('interest', 0.008974362440351826),\n",
       " ('sensor', 0.008913350631869543),\n",
       " ('trivialize', 0.008813678080443924),\n",
       " ('versa', 0.00876643920302268),\n",
       " ('everything', 0.008742309873117943),\n",
       " ('trust', 0.008667976893711777),\n",
       " ('idiot', 0.008356535403863783),\n",
       " ('clearly', 0.008202774096256265),\n",
       " ('illusion', 0.007960001905975745),\n",
       " ('um', 0.007928235673292016),\n",
       " ('vice', 0.007745283343155569),\n",
       " ('might', 0.007725788620965604),\n",
       " ('h', 0.007725540161813451),\n",
       " ('money', 0.007631991012975021),\n",
       " ('wise', 0.007617281274615149),\n",
       " ('low', 0.007362016194657937),\n",
       " ('incline', 0.007234859782207916),\n",
       " ('introspection', 0.007233953961434243),\n",
       " ('natural', 0.00710807829040001),\n",
       " ('would', 0.007098775212565853),\n",
       " ('fiered', 0.00697836420906271),\n",
       " ('hm', 0.006841973428097599),\n",
       " ('close', 0.006744490326191078),\n",
       " ('u', 0.006665840933546404),\n",
       " ('understand', 0.006582929198911338),\n",
       " ('damn', 0.006518224528337893),\n",
       " ('person', 0.006505522431849651),\n",
       " ('brother', 0.006410405669173991),\n",
       " ('etp', 0.00634240130585852),\n",
       " ('self', 0.006255570264877727),\n",
       " ('relevant', 0.006239082320246158),\n",
       " ('subreddit', 0.005698394278029847),\n",
       " ('profile', 0.005624449534963894),\n",
       " ('thing', 0.005608995232756647),\n",
       " ('trash', 0.005599074976466266),\n",
       " ('bore', 0.005374775219125477),\n",
       " ('hat', 0.005223919010381411),\n",
       " ('shudder', 0.0049676275261715),\n",
       " ('glamorous', 0.00447718019783095),\n",
       " ('deal', 0.0043685846443450435),\n",
       " ('lot', 0.004366636475406565),\n",
       " ('irrational', 0.004336883153565657),\n",
       " ('one', 0.0042304420272748005),\n",
       " ('side', 0.004209031923384243),\n",
       " ('mean', 0.004137716429738975),\n",
       " ('se', 0.004052530117871506),\n",
       " ('establishment', 0.003948095101326944),\n",
       " ('write', 0.0038444034177620074),\n",
       " ('blake', 0.0037929380466522407),\n",
       " ('tool', 0.003703015718038016),\n",
       " ('lenhy', 0.003540884079229823),\n",
       " ('comment', 0.003517374254174595),\n",
       " ('trap', 0.0034548496739648326),\n",
       " ('hey', 0.00338635594482304),\n",
       " ('think', 0.003193381623599382),\n",
       " ('f', 0.002978002974550606),\n",
       " ('camilla', 0.002942601067076175),\n",
       " ('celebritytypes', 0.002841767043579999),\n",
       " ('skew', 0.0025159715158929088),\n",
       " ('throw', 0.0017390277955241153),\n",
       " ('consciously', 0.0016399014389441283),\n",
       " ('much', 0.0014736582601995087),\n",
       " ('page', 0.0013823319909685528),\n",
       " ('justify', 0.0013276629892864404),\n",
       " ('direction', 0.001114649991780003),\n",
       " ('bear', 0.00028461733857895266),\n",
       " ('nd', 0.0001946370436654709),\n",
       " ('even', -8.901106106324548e-05),\n",
       " ('racism', -0.00036737038870430876),\n",
       " ('vocal', -0.00041050449342003737),\n",
       " ('incredible', -0.0004788915550063772),\n",
       " ('confront', -0.0006358263810242126),\n",
       " ('environment', -0.0006583191242603101),\n",
       " ('use', -0.0007323138294462849),\n",
       " ('mistyped', -0.0011003377021015785),\n",
       " ('imply', -0.0015378220233857203),\n",
       " ('attention', -0.0016631109281926386),\n",
       " ('connection', -0.0016718139564263386),\n",
       " ('implication', -0.0018530583310023927),\n",
       " ('function', -0.001963007546574263),\n",
       " ('dave', -0.002155243781971124),\n",
       " ('entirely', -0.0023019980176320334),\n",
       " ('correct', -0.002319129423334189),\n",
       " ('give', -0.0023586571874985537),\n",
       " ('anderson', -0.0023641905861048296),\n",
       " ('question', -0.0023939968680576906),\n",
       " ('deliberation', -0.0024744630420319123),\n",
       " ('encounter', -0.0024987948298091467),\n",
       " ('conclusion', -0.002565693480773289),\n",
       " ('young', -0.002802271253471868),\n",
       " ('philosopher', -0.0028674370820200206),\n",
       " ('maybe', -0.002927630397250469),\n",
       " ('talk', -0.0030366357193145803),\n",
       " ('racist', -0.00310014426719824),\n",
       " ('need', -0.0032929579040317783),\n",
       " ('high', -0.0034633310271399253),\n",
       " ('impossible', -0.003468233312695975),\n",
       " ('dead', -0.0036330278059219876),\n",
       " ('nah', -0.0037430960875185497),\n",
       " ('someone', -0.0038032675016374325),\n",
       " ('friend', -0.003825014393296223),\n",
       " ('eems', -0.0038641562767797824),\n",
       " ('definition', -0.004037093234718736),\n",
       " ('lso', -0.004225694826321966),\n",
       " ('nonetheless', -0.00464717713084488),\n",
       " ('seem', -0.0047040379632536525),\n",
       " ('yep', -0.0047676272618042016),\n",
       " ('precisely', -0.004977244489159401),\n",
       " ('flair', -0.004989543226379681),\n",
       " ('rankly', -0.005073631157251715),\n",
       " ('significant', -0.005188905959972016),\n",
       " ('try', -0.00537310024866574),\n",
       " ('ave', -0.0053757115614310475),\n",
       " ('away', -0.005595601536480323),\n",
       " ('hang', -0.005637525326615528),\n",
       " ('sister', -0.005650425496403138),\n",
       " ('quote', -0.005681223275047108),\n",
       " ('thinker', -0.00568300879560865),\n",
       " ('also', -0.005811451280180549),\n",
       " ('nothing', -0.005913785951774333),\n",
       " ('mechanism', -0.006242161253105829),\n",
       " ('animistic', -0.0064134736701079685),\n",
       " ('tie', -0.006468896258261087),\n",
       " ('activist', -0.006502065623817732),\n",
       " ('discrimination', -0.006704522420387806),\n",
       " ('inferior', -0.006863278427783364),\n",
       " ('n', -0.006891215322586341),\n",
       " ('hour', -0.006908386868319912),\n",
       " ('undertone', -0.007326290279433201),\n",
       " ('wander', -0.007350161036664997),\n",
       " ('really', -0.007406424370078628),\n",
       " ('quite', -0.007755645013520556),\n",
       " ('become', -0.00782565308563997),\n",
       " ('cause', -0.008064716605635685),\n",
       " ('miley', -0.008098455635220044),\n",
       " ('part', -0.008155675117445145),\n",
       " ('whatever', -0.008540801020250986),\n",
       " ('aware', -0.00863245322975811),\n",
       " ('drop', -0.008983424634327487),\n",
       " ('artist', -0.009033801286314527),\n",
       " ('christ', -0.009061003778438893),\n",
       " ('jesus', -0.00946604714455186),\n",
       " ('prove', -0.009592678483865583),\n",
       " ('demon', -0.009661288971140262),\n",
       " ('genre', -0.009875783659054987),\n",
       " ('ancient', -0.0099203218945982),\n",
       " ('see', -0.009951056758775795),\n",
       " ('einstein', -0.010978714371799127),\n",
       " ('bankrupt', -0.011220760091846199),\n",
       " ('top', -0.011228337993166387),\n",
       " ('sticky', -0.011438624188534897),\n",
       " ('kinda', -0.011593122463982662),\n",
       " ('misguide', -0.011651909976139317),\n",
       " ('however', -0.01204812561346895),\n",
       " ('emulate', -0.012194919385902826),\n",
       " ('animal', -0.012583704160123353),\n",
       " ('awareness', -0.01299332132685299),\n",
       " ('deep', -0.01348400452503037),\n",
       " ('great', -0.013570785214087368),\n",
       " ('fi', -0.014194568893737214),\n",
       " ('afraid', -0.01421673586337443),\n",
       " ('experience', -0.014289694930604772),\n",
       " ('survive', -0.01467776324009822),\n",
       " ('base', -0.014780062952742755),\n",
       " ('make', -0.01569192695705919),\n",
       " ('judge', -0.016089534012622485),\n",
       " ('opinion', -0.01615374173117789),\n",
       " ('relate', -0.01618069832707151),\n",
       " ('feel', -0.01751754906814291),\n",
       " ('suffocate', -0.017545940538915804),\n",
       " ('letter', -0.017573716383504173),\n",
       " ('energy', -0.017662087854476302),\n",
       " ('like', -0.019107003295604573),\n",
       " ('exposure', -0.019616667791578387),\n",
       " ('either', -0.019733162957734217),\n",
       " ('something', -0.01986346563495163),\n",
       " ('sense', -0.020039185027198342),\n",
       " ('itj', -0.020701263747063),\n",
       " ('sometimes', -0.0210357717783274),\n",
       " ('s', -0.021264440574876326),\n",
       " ('another', -0.022794919797993664),\n",
       " ('call', -0.024500213389414282),\n",
       " ('mountain', -0.028835826201961096)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort the explanation\n",
    "sorted_explanation_IE = sorted(lime_explanation_IE[0].as_list(),key=lambda x: x[1],reverse=True)\n",
    "sorted_explanation_IE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove the top 100 features and check the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a column to the extracted_df that contains with the text with the most important 100 tokens removed \n",
    "def remove_words(text,words):\n",
    "    for word in words:\n",
    "        text = text.replace(word,'')\n",
    "        # remove extra spaces\n",
    "        text = ' '.join(text.split())\n",
    "    return text\n",
    "def remove_100_tokens(lime_explanations,aspect):\n",
    "    for i in range(len(lime_explanations)):\n",
    "        # sort the words by importance\n",
    "        sorted_explanation = sorted(lime_explanations[i].as_list(),key=lambda x: x[1],reverse=True)\n",
    "        words = [word for word,weight in sorted_explanation[:100]]\n",
    "        extracted_df.loc[i,aspect+'_no_words'] = remove_words(extracted_df.loc[i,'text'],words)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_100_tokens(lime_explanation_IE,'IE')\n",
    "remove_100_tokens(lime_explanation_NS,'NS')\n",
    "remove_100_tokens(lime_explanation_TF,'TF')\n",
    "remove_100_tokens(lime_explanation_JP,'JP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the performance metrics for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/omarahmed/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/omarahmed/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# import model\n",
    "import sys\n",
    "sys.path.append('../Models')\n",
    "import roberta_mbti as model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roberta-base_no_words loaded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x2b9e0b290>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roberta_model = model.ROBERTAClass(PRE_TRAINED_MODEL_NAME)\n",
    "roberta_model.load_state_dict(torch.load(CHECKPOINTPATH + f'_clean_Best_{PRE_TRAINED_MODEL_NAME}.bin', map_location=torch.device(device)))\n",
    "roberta_model.to(device)\n",
    "print(f'{PRE_TRAINED_MODEL_NAME}_no_words loaded')\n",
    "roberta_model.eval()\n",
    "\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the predictions for the extracted_df IE_no_words , NS_no_words , TF_no_words , JP_no_words\n",
    "IE_no_words_pred=roberta_model.getPrediction(extracted_df['IE_no_words'].to_list())\n",
    "NS_no_words_pred=roberta_model.getPrediction(extracted_df['NS_no_words'].to_list())\n",
    "TF_no_words_pred=roberta_model.getPrediction(extracted_df['TF_no_words'].to_list())\n",
    "JP_no_words_pred=roberta_model.getPrediction(extracted_df['JP_no_words'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# round the predictions\n",
    "IE_no_words_pred = np.round(IE_no_words_pred)\n",
    "NS_no_words_pred = np.round(NS_no_words_pred)\n",
    "TF_no_words_pred = np.round(TF_no_words_pred)\n",
    "JP_no_words_pred = np.round(JP_no_words_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the predictions of the extracted_df IE_no_words , NS_no_words , TF_no_words , JP_no_words for each of the aspects\n",
    "extracted_df['IE_no_words_pred'] = IE_no_words_pred[:,0]\n",
    "extracted_df['NS_no_words_pred'] = NS_no_words_pred[:,1]\n",
    "extracted_df['TF_no_words_pred'] = TF_no_words_pred[:,2]\n",
    "extracted_df['JP_no_words_pred'] = JP_no_words_pred[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>IE</th>\n",
       "      <th>NS</th>\n",
       "      <th>TF</th>\n",
       "      <th>JP</th>\n",
       "      <th>IE_true</th>\n",
       "      <th>NS_true</th>\n",
       "      <th>TF_true</th>\n",
       "      <th>JP_true</th>\n",
       "      <th>IE_no_words</th>\n",
       "      <th>NS_no_words</th>\n",
       "      <th>TF_no_words</th>\n",
       "      <th>JP_no_words</th>\n",
       "      <th>IE_no_words_pred</th>\n",
       "      <th>NS_no_words_pred</th>\n",
       "      <th>TF_no_words_pred</th>\n",
       "      <th>JP_no_words_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>understand relate whatsoever close friend eith...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ndestand elate watsoeve fiend eite axiliay con...</td>\n",
       "      <td>destad e wtsoeve clo fied eithe domiat axiliay...</td>\n",
       "      <td>ersta whatsoever close frie dominant axiliary ...</td>\n",
       "      <td>undestand elate wsoeve close iend eithe inant ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>account net karma individual comment suggestio...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>account nt individual commnt bot many sub us d...</td>\n",
       "      <td>accout t karma idividual commt suggstio rddit ...</td>\n",
       "      <td>t karma idividual commt suggstio rddit bot may...</td>\n",
       "      <td>account net karma individual y u include defau...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text   IE   NS   TF   JP  \\\n",
       "0  understand relate whatsoever close friend eith...  1.0  1.0  1.0  1.0   \n",
       "1  account net karma individual comment suggestio...  1.0  1.0  1.0  1.0   \n",
       "\n",
       "   IE_true  NS_true  TF_true  JP_true  \\\n",
       "0      1.0      1.0      1.0      1.0   \n",
       "1      1.0      1.0      1.0      1.0   \n",
       "\n",
       "                                         IE_no_words  \\\n",
       "0  ndestand elate watsoeve fiend eite axiliay con...   \n",
       "1  account nt individual commnt bot many sub us d...   \n",
       "\n",
       "                                         NS_no_words  \\\n",
       "0  destad e wtsoeve clo fied eithe domiat axiliay...   \n",
       "1  accout t karma idividual commt suggstio rddit ...   \n",
       "\n",
       "                                         TF_no_words  \\\n",
       "0  ersta whatsoever close frie dominant axiliary ...   \n",
       "1  t karma idividual commt suggstio rddit bot may...   \n",
       "\n",
       "                                         JP_no_words  IE_no_words_pred  \\\n",
       "0  undestand elate wsoeve close iend eithe inant ...               0.0   \n",
       "1  account net karma individual y u include defau...               1.0   \n",
       "\n",
       "   NS_no_words_pred  TF_no_words_pred  JP_no_words_pred  \n",
       "0               0.0               0.0               1.0  \n",
       "1               0.0               0.0               0.0  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_df.head(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'IE': 0.77, 'NS': 0.87, 'TF': 0.58, 'JP': 0.84}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the accuracy of the extracted_df\n",
    "def get_accuracy_extracted_df_after(df,labels_list):\n",
    "    accuracy = {}\n",
    "    for label in labels_list:\n",
    "        accuracy[label] = (df[label+'_no_words_pred']==df[label+'_true']).sum()/len(df)\n",
    "    return accuracy\n",
    "\n",
    "get_accuracy_extracted_df_after(extracted_df,labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the accuracy drop in a json file\n",
    "import json\n",
    "accuracy_drop =get_accuracy_extracted_df_after(extracted_df,labels_list)\n",
    "with open('accuracy_drop.json', 'w') as f:\n",
    "    json.dump(accuracy_drop, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save intermediate results of the extracted_df\n",
    "extracted_df.to_csv('extracted_df.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
